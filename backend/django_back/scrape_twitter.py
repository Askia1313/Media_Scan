#!/usr/bin/env python3
"""
Script de scraping Twitter depuis la table media
R√©cup√®re les tweets des comptes Twitter configur√©s dans la table medias
"""

import argparse
import os
from dotenv import load_dotenv
from database.db_manager import DatabaseManager
from scrapers.twitter_scraper import TwitterScraper

# Charger les variables d'environnement
load_dotenv()


def scrape_twitter_for_media(db: DatabaseManager, tw_scraper: TwitterScraper,
                             media_id: int, media_nom: str, tw_account: str, limit: int = 10):
    """Scraper Twitter pour un m√©dia"""
    print(f"\nüê¶ Scraping Twitter: {media_nom} (@{tw_account})")
    
    try:
        result = tw_scraper.scrape_user(tw_account, max_results=limit)
        
        if result.get('error'):
            print(f"   ‚ùå Erreur: {result['error']}")
            return 0
        
        tweets = result.get('tweets', [])
        
        if not tweets:
            print(f"   ‚ö†Ô∏è Aucun tweet r√©cup√©r√©")
            return 0
        
        # Sauvegarder les tweets
        saved_count = 0
        for tweet in tweets:
            try:
                db.add_twitter_tweet(
                    media_id=media_id,
                    tweet_id=tweet['tweet_id'],
                    text=tweet['text'],
                    url=tweet['url'],
                    image_url=tweet.get('image_url'),
                    date_publication=tweet['date_publication'],
                    retweets=tweet['retweets'],
                    replies=tweet['replies'],
                    likes=tweet['likes'],
                    quotes=tweet['quotes'],
                    impressions=tweet['impressions']
                )
                saved_count += 1
            except Exception:
                continue
        
        stats = result.get('stats', {})
        print(f"   ‚úÖ {saved_count} tweets sauvegard√©s")
        print(f"   üìä Engagement total: {stats.get('total_engagement', 0):,}")
        
        return saved_count
    
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return 0


def main():
    parser = argparse.ArgumentParser(description='Scraping Twitter depuis table media')
    parser.add_argument('--media-id', type=int, help='ID d\'un m√©dia sp√©cifique')
    parser.add_argument('--all', action='store_true', help='Scraper tous les m√©dias avec Twitter')
    parser.add_argument('--limit', type=int, default=10, 
                       help='Nombre de tweets √† r√©cup√©rer par m√©dia (d√©faut: 10)')
    
    args = parser.parse_args()
    
    # V√©rifier le token Twitter
    tw_token = os.getenv('TWITTER_BEARER_TOKEN')
    if not tw_token:
        print("‚ùå Bearer Token Twitter manquant")
        print("üí° Configurez TWITTER_BEARER_TOKEN dans le fichier .env")
        return
    
    # Initialiser
    print("üîß Initialisation...")
    db = DatabaseManager()
    tw_scraper = TwitterScraper(tw_token)
    
    # Tester la connexion
    if not tw_scraper.test_connection():
        print("‚ùå Impossible de se connecter √† l'API Twitter")
        return
    
    print("‚úÖ Twitter API connect√©e\n")
    
    # Scraper un m√©dia sp√©cifique
    if args.media_id:
        # R√©cup√©rer le m√©dia
        medias = db.get_all_medias(actif_only=False)
        media = next((m for m in medias if m.id == args.media_id), None)
        
        if not media:
            print(f"‚ùå M√©dia ID {args.media_id} non trouv√©")
            return
        
        if not media.twitter_account:
            print(f"‚ùå Aucun compte Twitter configur√© pour {media.nom}")
            return
        
        print("="*60)
        print(f"üéØ Scraping: {media.nom}")
        print("="*60)
        
        scrape_twitter_for_media(
            db, tw_scraper, media.id, media.nom,
            media.twitter_account, args.limit
        )
    
    # Scraper tous les m√©dias avec Twitter
    elif args.all:
        print("="*60)
        print("üöÄ SCRAPING TWITTER MULTI-M√âDIAS")
        print("="*60)
        
        # R√©cup√©rer les m√©dias avec Twitter configur√©
        medias = db.get_medias_with_twitter(actif_only=True)
        
        if not medias:
            print("‚ùå Aucun m√©dia avec Twitter configur√©")
            print("üí° Ajoutez des comptes Twitter dans la table medias")
            return
        
        print(f"\nüìã {len(medias)} m√©dias √† scraper\n")
        
        total_tweets = 0
        
        for i, media in enumerate(medias, 1):
            print(f"[{i}/{len(medias)}] {media.nom}")
            print("-"*60)
            
            count = scrape_twitter_for_media(
                db, tw_scraper, media.id, media.nom,
                media.twitter_account, args.limit
            )
            
            total_tweets += count
        
        # R√©sum√©
        print("\n" + "="*60)
        print("üìä R√âSUM√â")
        print("="*60)
        print(f"‚úÖ Total tweets: {total_tweets}")
        
        # Afficher le top engagement
        print("\nüèÜ TOP ENGAGEMENT TWITTER (30 derniers jours):")
        ranking = db.get_media_ranking_with_twitter(days=30)
        
        for i, media in enumerate(ranking[:5], 1):
            if media['total_tweets'] > 0:
                print(f"\n{i}. {media['nom']}")
                print(f"   Tweets: {media['total_tweets']}")
                print(f"   Retweets: {media['total_retweets']:,}")
                print(f"   R√©ponses: {media['total_replies']:,}")
                print(f"   Likes: {media['total_likes_tw']:,}")
                print(f"   Quotes: {media['total_quotes']:,}")
                print(f"   Engagement total: {media['engagement_total_tw']:,}")
    
    else:
        print("‚ùå Sp√©cifiez --media-id ou --all")
        print("üí° Exemples:")
        print("   python scrape_twitter.py --all")
        print("   python scrape_twitter.py --media-id 1 --limit 20")


if __name__ == '__main__':
    main()
