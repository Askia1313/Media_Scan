

# üõ°Ô∏è Module de Mod√©ration de Contenu avec Ollama

## üéØ Objectif

D√©tecter automatiquement les contenus sensibles dans les articles, posts Facebook et tweets :
- **Incitation √† la haine** : Discours contre des groupes ethniques, religieux, etc.
- **Fake news / D√©sinformation** : Affirmations non v√©rifi√©es, manipulation de faits
- **Discours toxique** : Violence, insultes, discrimination
- **Contenus sensibles** : Terrorisme, conflits arm√©s, politique controvers√©e

## ‚úÖ Fonctionnalit√©s

### 1. Analyse de toxicit√©
- Incitation √† la haine (0-10)
- Violence et agressivit√© (0-10)
- Insultes et langage offensant (0-10)
- Discrimination (0-10)

### 2. D√©tection de d√©sinformation
- Affirmations non v√©rifi√©es (0-10)
- Manipulation de faits (0-10)
- Th√©ories du complot (0-10)
- Propagande (0-10)
- Identification d'√©l√©ments suspects

### 3. Analyse de sensibilit√©
- Violence ou conflit arm√©
- Terrorisme
- Politique controvers√©e
- Religion sensible
- Sant√© publique

### 4. Score de risque global
- Calcul pond√©r√© : 40% toxicit√© + 40% d√©sinformation + 20% sensibilit√©
- Niveaux : MINIMAL, FAIBLE, MOYEN, √âLEV√â, CRITIQUE
- Signalement automatique si score ‚â• 6/10

## üöÄ Installation

### 1. Installer Ollama

**Windows** :
```powershell
# T√©l√©charger depuis https://ollama.ai
# Ou avec winget
winget install Ollama.Ollama
```

**Linux/Mac** :
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. T√©l√©charger le mod√®le

```powershell
ollama pull llama3.2
```

### 3. Lancer Ollama

```powershell
ollama serve
```

Le serveur d√©marre sur `http://localhost:11434`

## üìä Utilisation

### Analyser tous les contenus

```powershell
python moderate_content.py --type all --limit 10
```

### Analyser uniquement les articles

```powershell
python moderate_content.py --type articles --limit 20
```

### Analyser les posts Facebook

```powershell
python moderate_content.py --type facebook --limit 15
```

### Analyser les tweets

```powershell
python moderate_content.py --type twitter --limit 15
```

### Analyser un m√©dia sp√©cifique

```powershell
python moderate_content.py --type all --media-id 1 --limit 10
```

### Afficher les contenus signal√©s

```powershell
python moderate_content.py --show-flagged
```

### Afficher les statistiques

```powershell
python moderate_content.py --stats
```

### Tester la connexion √† Ollama

```powershell
python moderate_content.py --test
```

## üìà Exemples de r√©sultats

### Analyse d'un article

```
üîç Analyse de l'article 123: Tensions politiques au Burkina Faso...
   üö® SIGNAL√â - üü† √âLEV√â (Score: 7.2)
      ‚ö†Ô∏è Toxique: Contient des propos discriminatoires
      ‚ö†Ô∏è Sensible: Aborde un conflit politique sensible
```

### Analyse d'un post Facebook

```
üîç Analyse du post 456: Message controvers√©...
   ‚úÖ OK - üü° MOYEN (Score: 3.5)
```

### Contenus signal√©s

```
üö® Contenus signal√©s
================================================================================

üî¥ CRITIQUE - ARTICLE #789
   Score de risque: 8.5/10
   Signalements: Toxique, D√©sinformation
   Analys√© le: 2025-11-16 10:30:00

üü† √âLEV√â - TWEET #456
   Score de risque: 6.8/10
   Signalements: Toxique, Sensible
   Analys√© le: 2025-11-16 10:25:00
```

### Statistiques

```
üìä Statistiques de mod√©ration
================================================================================
Total analys√©: 50
Total signal√©: 8
Contenus toxiques: 5
D√©sinformation: 3
Contenus sensibles: 12
Score de risque moyen: 3.2/10

Taux de signalement: 16.0%
```

## üîß Int√©gration dans le workflow

### Apr√®s le scraping

```powershell
# 1. Scraper les contenus
python scrape_with_social.py --all

# 2. Analyser les contenus
python moderate_content.py --type all --limit 50

# 3. Voir les contenus signal√©s
python moderate_content.py --show-flagged
```

### Automatisation quotidienne

Cr√©ez un script PowerShell :

```powershell
# daily_moderation.ps1
cd C:\Users\DarkSide\Desktop\Media_Scanne\backend\django_back
env\Scripts\activate

# Scraping
python scrape_with_social.py --all --fb-posts 5 --tweets 5

# Mod√©ration
python moderate_content.py --type all --limit 100

# Rapport des contenus signal√©s
python moderate_content.py --show-flagged > reports/flagged_$(Get-Date -Format 'yyyy-MM-dd').txt

# Statistiques
python moderate_content.py --stats > reports/moderation_stats_$(Get-Date -Format 'yyyy-MM-dd').txt
```

## üìä Structure de la base de donn√©es

### Table `content_moderation`

```sql
CREATE TABLE content_moderation (
    id INTEGER PRIMARY KEY,
    content_type TEXT,  -- 'article', 'facebook_post', 'tweet'
    content_id INTEGER,
    
    -- Scores globaux
    risk_score REAL,
    risk_level TEXT,
    should_flag BOOLEAN,
    
    -- Toxicit√©
    is_toxic BOOLEAN,
    toxicity_score REAL,
    hate_speech_score REAL,
    violence_score REAL,
    insults_score REAL,
    discrimination_score REAL,
    
    -- D√©sinformation
    is_misinformation BOOLEAN,
    misinformation_score REAL,
    unverified_claims_score REAL,
    fact_manipulation_score REAL,
    conspiracy_score REAL,
    propaganda_score REAL,
    suspicious_elements TEXT,
    
    -- Sensibilit√©
    is_sensitive BOOLEAN,
    sensitivity_level TEXT,
    sensitivity_score REAL,
    sensitive_categories TEXT,
    
    analyzed_at TIMESTAMP,
    model_used TEXT
);
```

## üé® Niveaux de risque

| Score | Niveau | Ic√¥ne | Action |
|-------|--------|-------|--------|
| 0-2 | MINIMAL | ‚úÖ | Aucune action |
| 2-4 | FAIBLE | üü¢ | Surveillance |
| 4-6 | MOYEN | üü° | Attention |
| 6-8 | √âLEV√â | üü† | Signalement |
| 8-10 | CRITIQUE | üî¥ | Alerte imm√©diate |

## üîç Crit√®res de d√©tection

### Toxicit√©
- Langage haineux contre des groupes
- Appels √† la violence
- Insultes et attaques personnelles
- Discrimination ethnique/religieuse

### D√©sinformation
- Affirmations sans sources
- Manipulation de statistiques
- Th√©ories du complot
- Propagande politique

### Sensibilit√©
- Conflits arm√©s et terrorisme
- Crises politiques
- Questions religieuses sensibles
- √âpid√©mies et sant√© publique

## üí° Bonnes pratiques

### 1. Analyser r√©guli√®rement
```powershell
# Tous les jours
python moderate_content.py --type all --limit 50
```

### 2. Surveiller les contenus signal√©s
```powershell
# V√©rifier les alertes
python moderate_content.py --show-flagged
```

### 3. Ajuster les seuils
Le score de risque peut √™tre ajust√© dans `content_moderator.py` :
```python
def _calculate_risk_score(self, toxicity, misinformation, sensitivity):
    # Modifier les pond√©rations selon vos besoins
    risk_score = (
        toxicity_score * 0.4 +  # 40% toxicit√©
        misinfo_score * 0.4 +   # 40% d√©sinformation
        sensitivity_score * 0.2  # 20% sensibilit√©
    )
    return risk_score
```

### 4. Utiliser diff√©rents mod√®les
```python
# Dans content_moderator.py
moderator = ContentModerator(model="llama3.2")  # Par d√©faut
moderator = ContentModerator(model="mistral")   # Alternative
```

## üö® Limitations

1. **D√©pend d'Ollama** : Le serveur Ollama doit √™tre lanc√©
2. **Temps d'analyse** : ~5-10 secondes par contenu
3. **Pr√©cision** : Le mod√®le peut avoir des faux positifs/n√©gatifs
4. **Langue** : Optimis√© pour le fran√ßais
5. **Contexte** : L'analyse est bas√©e sur le texte uniquement

## üîß D√©pannage

### Erreur : "Impossible de se connecter √† Ollama"

```powershell
# V√©rifier qu'Ollama est lanc√©
ollama serve

# V√©rifier que le mod√®le est install√©
ollama list

# T√©l√©charger le mod√®le si n√©cessaire
ollama pull llama3.2
```

### Analyse trop lente

```powershell
# R√©duire le nombre de contenus
python moderate_content.py --type articles --limit 5

# Utiliser un mod√®le plus rapide
# Modifier model="llama3.2" en model="phi" dans content_moderator.py
```

### Faux positifs

- Ajuster les seuils dans `_determine_risk_level()`
- Modifier les pond√©rations dans `_calculate_risk_score()`
- Utiliser un mod√®le diff√©rent

## üìö Ressources

- **Ollama** : https://ollama.ai
- **Mod√®les disponibles** : https://ollama.ai/library
- **Documentation Ollama** : https://github.com/ollama/ollama

## ‚úÖ R√©sum√©

Le module de mod√©ration permet de :
- ‚úÖ D√©tecter automatiquement les contenus toxiques
- ‚úÖ Identifier la d√©sinformation et les fake news
- ‚úÖ Rep√©rer les contenus sensibles
- ‚úÖ Calculer un score de risque global
- ‚úÖ Signaler les contenus probl√©matiques
- ‚úÖ G√©n√©rer des statistiques de mod√©ration

**La mod√©ration de contenu est op√©rationnelle ! üõ°Ô∏èüöÄ**
