#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de test pour v√©rifier le scraping
"""

import sys
from pathlib import Path

# Ajouter le dossier parent au PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent))

from database.db_manager import DatabaseManager
from scrapers.wordpress_scraper import WordPressScraper
from scrapers.html_scraper import HTMLScraper


def test_wordpress_detection():
    """Tester la d√©tection WordPress"""
    print("\n" + "="*60)
    print("TEST 1: D√©tection WordPress")
    print("="*60)
    
    test_sites = [
        'https://lefaso.net',
        'https://www.sidwaya.info',
        'https://www.fasopresse.net'
    ]
    
    for url in test_sites:
        print(f"\nüîç Test: {url}")
        scraper = WordPressScraper(url)
        is_wp = scraper.is_wordpress()
        
        if is_wp:
            print(f"   ‚úÖ WordPress d√©tect√©")
        else:
            print(f"   ‚ùå WordPress non d√©tect√©")


def test_wordpress_scraping():
    """Tester le scraping WordPress"""
    print("\n" + "="*60)
    print("TEST 2: Scraping WordPress")
    print("="*60)
    
    # Initialiser la base de donn√©es
    db = DatabaseManager('data/test_media_scan.db')
    
    # Tester avec Lefaso.net (probablement WordPress)
    url = 'https://lefaso.net'
    print(f"\nüì° Test scraping: {url}")
    
    try:
        scraper = WordPressScraper(url)
        
        if scraper.is_wordpress():
            # Ajouter le m√©dia
            media_id = db.add_media('Lefaso.net', url, 'wordpress')
            
            # Scraper (limit√© √† 5 articles pour le test)
            articles = scraper.scrape(media_id, days=30)
            
            print(f"\n‚úÖ {len(articles)} articles r√©cup√©r√©s")
            
            # Afficher les 3 premiers
            for i, article in enumerate(articles[:3], 1):
                print(f"\n   Article {i}:")
                print(f"   ‚Ä¢ Titre: {article.titre[:80]}...")
                print(f"   ‚Ä¢ URL: {article.url}")
                print(f"   ‚Ä¢ Date: {article.date_publication}")
                print(f"   ‚Ä¢ Auteur: {article.auteur}")
                print(f"   ‚Ä¢ Contenu: {len(article.contenu)} caract√®res")
            
            # Sauvegarder en base
            saved = 0
            for article in articles:
                if db.add_article(article):
                    saved += 1
            
            print(f"\nüíæ {saved} articles sauvegard√©s en base de donn√©es")
        
        else:
            print("‚ùå Ce site n'utilise pas WordPress")
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()


def test_html_scraping():
    """Tester le scraping HTML"""
    print("\n" + "="*60)
    print("TEST 3: Scraping HTML")
    print("="*60)
    
    # Initialiser la base de donn√©es
    db = DatabaseManager('data/test_media_scan.db')
    
    # Tester avec un site
    url = 'https://www.aib.media'
    print(f"\nüåê Test scraping HTML: {url}")
    
    try:
        scraper = HTMLScraper(url)
        
        # Ajouter le m√©dia
        media_id = db.add_media('AIB', url, 'html')
        
        # Scraper (limit√© √† 5 articles pour le test)
        articles = scraper.scrape(media_id, days=30, max_articles=5)
        
        print(f"\n‚úÖ {len(articles)} articles r√©cup√©r√©s")
        
        # Afficher les articles
        for i, article in enumerate(articles, 1):
            print(f"\n   Article {i}:")
            print(f"   ‚Ä¢ Titre: {article.titre[:80]}...")
            print(f"   ‚Ä¢ URL: {article.url}")
            print(f"   ‚Ä¢ Contenu: {len(article.contenu)} caract√®res")
        
        # Sauvegarder en base
        saved = 0
        for article in articles:
            if db.add_article(article):
                saved += 1
        
        print(f"\nüíæ {saved} articles sauvegard√©s en base de donn√©es")
    
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()


def test_database():
    """Tester les op√©rations de base de donn√©es"""
    print("\n" + "="*60)
    print("TEST 4: Base de donn√©es")
    print("="*60)
    
    db = DatabaseManager('data/test_media_scan.db')
    
    # Statistiques
    stats = db.get_scraping_stats()
    
    print(f"\nüìä Statistiques:")
    print(f"   ‚Ä¢ Total articles: {stats['total_articles']}")
    print(f"   ‚Ä¢ Articles par m√©dia: {stats['articles_par_media']}")
    print(f"   ‚Ä¢ Articles par source: {stats['articles_par_source']}")
    
    # R√©cup√©rer les articles r√©cents
    recent = db.get_recent_articles(days=30, limit=5)
    
    print(f"\nüì∞ {len(recent)} articles r√©cents:")
    for article in recent:
        print(f"   ‚Ä¢ {article.titre[:60]}... ({article.date_publication})")


def main():
    """Fonction principale"""
    print("\n" + "="*60)
    print("üß™ TESTS DU SYST√àME DE SCRAPING")
    print("="*60)
    
    try:
        # Test 1: D√©tection WordPress
        test_wordpress_detection()
        
        # Test 2: Scraping WordPress
        test_wordpress_scraping()
        
        # Test 3: Scraping HTML
        test_html_scraping()
        
        # Test 4: Base de donn√©es
        test_database()
        
        print("\n" + "="*60)
        print("‚úÖ TESTS TERMIN√âS")
        print("="*60)
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Tests interrompus")
    except Exception as e:
        print(f"\n‚ùå Erreur globale: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
