# üì∞ Media Scanner - Backend API

API REST Django pour le scraping, l'analyse et la mod√©ration de contenus m√©diatiques burkinab√®. Ce backend collecte automatiquement des articles de presse, posts Facebook et tweets, puis les analyse avec classification th√©matique et mod√©ration de contenu.

## üèóÔ∏è Architecture

```
backend/
‚îú‚îÄ‚îÄ django_back/
‚îÇ   ‚îú‚îÄ‚îÄ django_back/          # Configuration Django principale
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ settings.py       # Configuration globale
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ urls.py           # Routes principales + Swagger
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ wsgi.py           # Point d'entr√©e WSGI
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/                  # Application API REST
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ views.py          # Endpoints REST (m√©dias, articles, stats, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ urls.py           # Routes API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ serializers.py    # S√©rialiseurs DRF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scheduler.py      # Automatisation du scraping
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ apps.py           # Configuration de l'app
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ database/             # Gestion de la base de donn√©es
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_manager.py     # Gestionnaire SQLite (CRUD)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py         # Mod√®les de donn√©es (dataclasses)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schema.sql        # Sch√©ma de base de donn√©es
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/             # Modules de scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper_manager.py      # Gestionnaire principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rss_scraper.py          # Scraping RSS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ smart_html_scraper.py   # Scraping HTML intelligent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ facebook_scraper.py     # Scraping Facebook
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ twitter_scraper.py      # Scraping Twitter
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ analysis/             # Modules d'analyse
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ theme_classifier.py     # Classification th√©matique (Ollama + Mistral)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audience_analyzer.py    # Analyse d'audience multi-plateformes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ content_moderator.py    # Mod√©ration de contenu (toxicit√©, fake news)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                # Utilitaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ date_utils.py     # Gestion des dates
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_utils.py     # Traitement de texte
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ manage.py             # CLI Django
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt      # D√©pendances Python
‚îÇ   ‚îú‚îÄ‚îÄ scrape_with_social.py # Script de scraping complet
‚îÇ   ‚îú‚îÄ‚îÄ classify_articles.py  # Script de classification
‚îÇ   ‚îú‚îÄ‚îÄ moderate_content.py   # Script de mod√©ration
‚îÇ   ‚îî‚îÄ‚îÄ show_audience.py      # Script d'analyse d'audience
‚îÇ
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ media_scan.db         # Base de donn√©es SQLite
```

## üõ†Ô∏è Technologies

### Framework & API

- **Django 5.2.8** - Framework web Python
- **Django REST Framework 3.14.0** - API REST
- **drf-yasg 1.21.7** - Documentation Swagger/OpenAPI
- **django-cors-headers 4.3.1** - Gestion CORS

### Scraping & Parsing

- **requests 2.31.0** - Requ√™tes HTTP
- **beautifulsoup4 4.12.2** - Parsing HTML
- **feedparser 6.0.10** - Parsing RSS/Atom

### Base de donn√©es

- **SQLite 3** - Base de donn√©es embarqu√©e

### IA & Analyse

- **Ollama + Mistral** - Classification th√©matique (externe)
- **Ollama + **Mistral****- Mod√©ration de contenu (externe)

### Utilitaires

- **python-dateutil 2.8.2** - Manipulation de dates
- **python-dotenv 1.0.0** - Variables d'environnement

## üìä Base de donn√©es

### Sch√©ma principal

#### Table `medias`

Stocke les m√©dias √† surveiller.

| Colonne               | Type      | Description                   |
| --------------------- | --------- | ----------------------------- |
| `id`                | INTEGER   | Cl√© primaire                 |
| `nom`               | TEXT      | Nom du m√©dia                 |
| `url`               | TEXT      | URL du site (unique)          |
| `type_site`         | TEXT      | Type : wordpress, html, autre |
| `facebook_page`     | TEXT      | Nom/ID de la page Facebook    |
| `twitter_account`   | TEXT      | Compte Twitter (sans @)       |
| `actif`             | BOOLEAN   | M√©dia actif ou non           |
| `derniere_collecte` | TIMESTAMP | Date de derni√®re collecte    |
| `created_at`        | TIMESTAMP | Date de cr√©ation             |

#### Table `articles`

Stocke les articles collect√©s.

| Colonne              | Type      | Description                  |
| -------------------- | --------- | ---------------------------- |
| `id`               | INTEGER   | Cl√© primaire                |
| `media_id`         | INTEGER   | R√©f√©rence au m√©dia        |
| `titre`            | TEXT      | Titre de l'article           |
| `contenu`          | TEXT      | Contenu complet              |
| `extrait`          | TEXT      | Extrait/r√©sum√©             |
| `url`              | TEXT      | URL de l'article (unique)    |
| `auteur`           | TEXT      | Auteur                       |
| `date_publication` | TIMESTAMP | Date de publication          |
| `image_url`        | TEXT      | URL de l'image               |
| `categories`       | TEXT      | Cat√©gories (JSON)           |
| `tags`             | TEXT      | Tags (JSON)                  |
| `source_type`      | TEXT      | wordpress_api, html_scraping |
| `vues`             | INTEGER   | Nombre de vues               |
| `commentaires`     | INTEGER   | Nombre de commentaires       |
| `scraped_at`       | TIMESTAMP | Date de scraping             |
| `created_at`       | TIMESTAMP | Date de cr√©ation            |

#### Table `classifications`

Classifications th√©matiques des articles.

| Colonne           | Type      | Description                                                      |
| ----------------- | --------- | ---------------------------------------------------------------- |
| `id`            | INTEGER   | Cl√© primaire                                                    |
| `article_id`    | INTEGER   | R√©f√©rence √† l'article (unique)                                |
| `categorie`     | TEXT      | Politique, √âconomie, S√©curit√©, Sant√©, Culture, Sport, Autres |
| `confiance`     | REAL      | Score de confiance (0-1)                                         |
| `mots_cles`     | TEXT      | Mots-cl√©s (JSON)                                                |
| `justification` | TEXT      | Explication de la classification                                 |
| `methode`       | TEXT      | mistral_ollama, keywords_fallback                                |
| `created_at`    | TIMESTAMP | Date de cr√©ation                                                |

#### Table `facebook_posts`

Posts Facebook collect√©s.

| Colonne              | Type      | Description            |
| -------------------- | --------- | ---------------------- |
| `id`               | INTEGER   | Cl√© primaire          |
| `media_id`         | INTEGER   | R√©f√©rence au m√©dia  |
| `post_id`          | TEXT      | ID Facebook (unique)   |
| `message`          | TEXT      | Contenu du post        |
| `url`              | TEXT      | URL du post            |
| `image_url`        | TEXT      | URL de l'image         |
| `date_publication` | TIMESTAMP | Date de publication    |
| `likes`            | INTEGER   | Nombre de likes        |
| `comments`         | INTEGER   | Nombre de commentaires |
| `shares`           | INTEGER   | Nombre de partages     |
| `engagement_total` | INTEGER   | Engagement total       |
| `scraped_at`       | TIMESTAMP | Date de scraping       |

#### Table `twitter_tweets`

Tweets collect√©s.

| Colonne              | Type      | Description           |
| -------------------- | --------- | --------------------- |
| `id`               | INTEGER   | Cl√© primaire         |
| `media_id`         | INTEGER   | R√©f√©rence au m√©dia |
| `tweet_id`         | TEXT      | ID Twitter (unique)   |
| `text`             | TEXT      | Contenu du tweet      |
| `url`              | TEXT      | URL du tweet          |
| `image_url`        | TEXT      | URL de l'image        |
| `date_publication` | TIMESTAMP | Date de publication   |
| `retweets`         | INTEGER   | Nombre de retweets    |
| `replies`          | INTEGER   | Nombre de r√©ponses   |
| `likes`            | INTEGER   | Nombre de likes       |
| `quotes`           | INTEGER   | Nombre de citations   |
| `impressions`      | INTEGER   | Nombre d'impressions  |
| `engagement_total` | INTEGER   | Engagement total      |
| `scraped_at`       | TIMESTAMP | Date de scraping      |

#### Table `content_moderation`

Analyses de mod√©ration de contenu.

| Colonne                  | Type      | Description                                 |
| ------------------------ | --------- | ------------------------------------------- |
| `id`                   | INTEGER   | Cl√© primaire                               |
| `content_type`         | TEXT      | article, facebook_post, tweet               |
| `content_id`           | INTEGER   | ID du contenu                               |
| `risk_score`           | REAL      | Score de risque (0-10)                      |
| `risk_level`           | TEXT      | MINIMAL, FAIBLE, MOYEN, √âLEV√â, CRITIQUE   |
| `should_flag`          | BOOLEAN   | Contenu √† signaler                         |
| `is_toxic`             | BOOLEAN   | Contenu toxique                             |
| `toxicity_score`       | REAL      | Score de toxicit√©                          |
| `is_misinformation`    | BOOLEAN   | D√©sinformation d√©tect√©e                  |
| `misinformation_score` | REAL      | Score de d√©sinformation                    |
| `is_sensitive`         | BOOLEAN   | Contenu sensible                            |
| `sensitivity_score`    | REAL      | Score de sensibilit√©                       |
| `primary_issue`        | TEXT      | toxicity, misinformation, sensitivity, none |
| `analyzed_at`          | TIMESTAMP | Date d'analyse                              |
| `model_used`           | TEXT      | Mod√®le IA utilis√©                         |

## üîå API REST

### Documentation interactive

- **Swagger UI** : `http://localhost:8000/swagger/`
- **ReDoc** : `http://localhost:8000/redoc/`
- **JSON Schema** : `http://localhost:8000/swagger.json`

### Endpoints principaux

#### üè• Health Check

```
GET /api/health/
```

V√©rification de l'√©tat du serveur.

#### üì∞ M√©dias

```
GET    /api/medias/              # Liste tous les m√©dias
GET    /api/medias/?actif=true   # M√©dias actifs uniquement
POST   /api/medias/              # Cr√©er un nouveau m√©dia
GET    /api/medias/{id}/         # D√©tails d'un m√©dia
PUT    /api/medias/{id}/         # Mettre √† jour un m√©dia
DELETE /api/medias/{id}/         # Supprimer un m√©dia
```

**Exemple de cr√©ation de m√©dia :**

```json
POST /api/medias/
{
  "nom": "AIB",
  "url": "https://www.aib.media",
  "type_site": "wordpress",
  "facebook_page": "AIBBurkinaFaso",
  "twitter_account": "AibBurkina"
}
```

#### üìÑ Articles

```
GET /api/articles/                    # Liste des articles r√©cents
GET /api/articles/?media_id=1         # Articles d'un m√©dia
GET /api/articles/?days=7&limit=100   # Articles des 7 derniers jours
```

**Param√®tres de requ√™te :**

- `media_id` : Filtrer par m√©dia
- `days` : Nombre de jours (d√©faut: 7)
- `limit` : Nombre max de r√©sultats (d√©faut: 100)

#### üè∑Ô∏è Classifications

```
GET /api/classifications/                      # Liste des classifications
GET /api/classifications/?categorie=Politique  # Par cat√©gorie
GET /api/classifications/stats/?days=30        # Statistiques par cat√©gorie
GET /api/classifications/weekly/?weeks=5       # Stats hebdomadaires
```

**Cat√©gories disponibles :**

- Politique
- √âconomie
- S√©curit√©
- Sant√©
- Culture
- Sport
- Autres

#### üìò Facebook

```
GET /api/facebook/posts/?media_id=1&limit=100
```

Liste des posts Facebook d'un m√©dia.

#### üê¶ Twitter

```
GET /api/twitter/tweets/?media_id=1&limit=100
```

Liste des tweets d'un m√©dia.

#### üë• Audience

```
GET /api/audience/web/?days=30        # Audience Web (articles)
GET /api/audience/facebook/?days=30   # Audience Facebook
GET /api/audience/twitter/?days=30    # Audience Twitter
GET /api/audience/global/?days=30     # Audience globale combin√©e
GET /api/audience/inactive/?days_threshold=7  # M√©dias inactifs
```

#### üèÜ Classement

```
GET /api/ranking/?days=30
```

Classement des m√©dias par engagement total.

#### üîÑ Scraping

```
POST /api/scraping/trigger/    # D√©clencher un scraping manuel
GET  /api/scraping/schedule/   # Configuration du scraping automatique
PUT  /api/scraping/schedule/   # Modifier la configuration
GET  /api/scraping/history/    # Historique des t√¢ches
```

**Exemple de d√©clenchement manuel :**

```json
POST /api/scraping/trigger/
{
  "all": true,
  "days": 7,
  "fb_posts": 10,
  "tweets": 10,
  "skip_facebook": false,
  "skip_twitter": false
}
```

**Configuration du scraping automatique :**

```json
PUT /api/scraping/schedule/
{
  "enabled": true,
  "frequency": "daily",
  "days": 7,
  "fb_posts": 10,
  "tweets": 10
}
```

**Fr√©quences disponibles :**

- `hourly` : Toutes les heures
- `daily` : Tous les jours
- `weekly` : Toutes les semaines

#### üõ°Ô∏è Mod√©ration

```
GET  /api/moderation/stats/          # Statistiques de mod√©ration
GET  /api/moderation/flagged/        # Contenus signal√©s
POST /api/moderation/content/        # Mod√©rer un contenu
```

**Exemple de mod√©ration :**

```json
POST /api/moderation/content/
{
  "content_type": "article",
  "content_id": 123
}
```

#### üìä Statistiques

```
GET /api/stats/
```

Vue d'ensemble des statistiques globales.

## üöÄ Installation

### Pr√©requis

- Python 3.10+
- SQLite 3
- Ollama (optionnel, pour classification et mod√©ration)

### Installation des d√©pendances

```bash
cd backend/django_back
pip install -r requirements.txt
```

### Configuration

1. **Cr√©er le fichier [.env](cci:7://file:///c:/Users/DarkSide/Desktop/Media_Scanne/backend/django_back/.env:0:0-0:0)** (optionnel) :

```bash
cp .env.example .env
```

2. **Variables d'environnement** ([.env](cci:7://file:///c:/Users/DarkSide/Desktop/Media_Scanne/backend/django_back/.env:0:0-0:0)) :

```env
DEBUG=True
SECRET_KEY=your-secret-key-here
ALLOWED_HOSTS=localhost,127.0.0.1
DATABASE_PATH=../../data/media_scan.db
OLLAMA_URL=http://localhost:11434
```

### Lancement du serveur

```bash
python manage.py runserver
```

Le serveur d√©marre sur `http://localhost:8000/`

## üîß Utilisation

### Scripts CLI disponibles

#### 1. Scraping complet (Web + Social)

```bash
# Scraper tous les m√©dias actifs
python scrape_with_social.py --all --days 7 --fb-posts 10 --tweets 10

# Scraper un m√©dia sp√©cifique
python scrape_with_social.py --url https://www.aib.media --days 30

# Sans Facebook
python scrape_with_social.py --all --skip-facebook

# Sans Twitter
python scrape_with_social.py --all --skip-twitter
```

**Options :**

- `--all` : Scraper tous les m√©dias actifs
- `--url URL` : Scraper un m√©dia sp√©cifique
- `--days N` : Nombre de jours √† r√©cup√©rer (d√©faut: 7)
- `--fb-posts N` : Nombre de posts Facebook (d√©faut: 10)
- `--tweets N` : Nombre de tweets (d√©faut: 10)
- `--skip-facebook` : Ignorer Facebook
- `--skip-twitter` : Ignorer Twitter

#### 2. Classification th√©matique

```bash
# Classifier les articles non classifi√©s
python classify_articles.py

# Classifier les N derniers articles
python classify_articles.py --limit 100

# Reclassifier tous les articles
python classify_articles.py --reclassify
```

#### 3. Mod√©ration de contenu

```bash
# Mod√©rer les contenus non analys√©s
python moderate_content.py

# Mod√©rer les N derniers contenus
python moderate_content.py --limit 50

# Remod√©rer tous les contenus
python moderate_content.py --reanalyze
```

#### 4. Analyse d'audience

```bash
# Afficher l'analyse d'audience
python show_audience.py

# P√©riode personnalis√©e
python show_audience.py --days 30
```

### Scraping automatique

Le scraping automatique est g√©r√© par le scheduler int√©gr√©. Configuration via l'API :

```bash
# Activer le scraping quotidien
curl -X PUT http://localhost:8000/api/scraping/schedule/ \
  -H "Content-Type: application/json" \
  -d '{
    "enabled": true,
    "frequency": "daily",
    "days": 7,
    "fb_posts": 10,
    "tweets": 10
  }'
```

## üß© Modules principaux

### 1. Scraper Manager ([scrapers/scraper_manager.py](cci:7://file:///c:/Users/DarkSide/Desktop/Media_Scanne/backend/django_back/scrapers/scraper_manager.py:0:0-0:0))

Gestionnaire intelligent de scraping avec fallback automatique :

1. **RSS Feed** (prioritaire) - Rapide et fiable
2. **HTML Scraping** (fallback) - Si RSS indisponible

**Fonctionnalit√©s :**

- D√©tection automatique du type de site
- Classification automatique apr√®s scraping
- Gestion des erreurs et retry
- Logging d√©taill√©

### 2. Theme Classifier ([analysis/theme_classifier.py](cci:7://file:///c:/Users/DarkSide/Desktop/Media_Scanne/backend/django_back/analysis/theme_classifier.py:0:0-0:0))

Classification th√©matique utilisant **Ollama + Mistral** :

**Cat√©gories :**

- Politique
- √âconomie
- S√©curit√©
- Sant√©
- Culture
- Sport
- Autres

**M√©thode :**

- Analyse du titre et contenu avec Mistral
- Score de confiance (0-1)
- Extraction de mots-cl√©s
- Justification de la classification
- Fallback sur mots-cl√©s si Ollama indisponible

### 3. Audience Analyzer ([analysis/audience_analyzer.py](cci:7://file:///c:/Users/DarkSide/Desktop/Media_Scanne/backend/django_back/analysis/audience_analyzer.py:0:0-0:0))

Analyse d'audience multi-plateformes :

**M√©triques Web :**

- Nombre d'articles
- Fr√©quence de publication
- Articles par jour
- Statut d'activit√©

**M√©triques Facebook :**

- Posts, likes, commentaires, partages
- Engagement total et moyen
- Fr√©quence de publication

**M√©triques Twitter :**

- Tweets, retweets, replies, likes
- Impressions
- Engagement total et moyen

**Score d'influence :**

- Composite : 40% volume + 60% engagement
- Classement des m√©dias

### 4. Content Moderator (`analysis/content_moderator.py`)

Mod√©ration de contenu avec **Ollama + Mistral**:

**D√©tections :**

- **Toxicit√©** : discours haineux, violence, insultes, discrimination
- **D√©sinformation** : fake news, manipulation, propagande, th√©ories du complot
- **Sensibilit√©** : contenu sensible n√©cessitant attention

**Scores :**

- Score de risque global (0-10)
- Niveau de risque : MINIMAL, FAIBLE, MOYEN, √âLEV√â, CRITIQUE
- Signalement automatique si n√©cessaire

### 5. Database Manager (`database/db_manager.py`)

Gestionnaire SQLite avec m√©thodes CRUD compl√®tes :

**Fonctionnalit√©s :**

- Gestion des m√©dias, articles, classifications
- Posts Facebook et tweets
- M√©triques d'audience
- Historique de scraping
- Mod√©ration de contenu
- Transactions s√©curis√©es

## üîê S√©curit√©

### Configuration de production

**‚ö†Ô∏è Important pour la production :**

1. **Changer la SECRET_KEY** dans `settings.py`
2. **D√©sactiver DEBUG** : `DEBUG = False`
3. **Configurer ALLOWED_HOSTS** : liste des domaines autoris√©s
4. **D√©sactiver CORS_ALLOW_ALL_ORIGINS** : configurer les origines sp√©cifiques
5. **Utiliser HTTPS** en production
6. **Configurer les permissions REST Framework** si n√©cessaire

### Variables sensibles

Utiliser des variables d'environnement pour :

- `SECRET_KEY`
- Cl√©s API
- URLs de services externes
- Identifiants de base de donn√©es

## Optimisations

- **Index SQLite** sur colonnes fr√©quemment requ√™t√©es
- **Pagination** : 100 r√©sultats par d√©faut
- **Cache** : possibilit√© d'ajouter Redis pour cache
- **Async** : possibilit√© de passer √† Django Async pour scraping parall√®le

### Limites actuelles

- SQLite : adapt√© jusqu'√† ~100k articles
- Scraping synchrone : 1 m√©dia √† la fois
- Ollama : n√©cessite ressources locales

### √âvolutions possibles

- Migration vers PostgreSQL pour gros volumes
- Scraping asynchrone avec Celery
- Cache Redis
- API rate limiting
- Authentification JWT

## üêõ D√©bogage

### Logs

Les logs sont affich√©s dans la console du serveur Django.

### V√©rifier l'√©tat de la base de donn√©es

```bash
python check_tables.py
```

### Tester les endpoints

```bash
# Health check
curl http://localhost:8000/api/health/

# Liste des m√©dias
curl http://localhost:8000/api/medias/

# Articles r√©cents
curl http://localhost:8000/api/articles/?days=7&limit=10
```

## üìù License

Ce projet est d√©velopp√© dans le cadre du Media Scanner pour l'analyse des m√©dias burkinab√®.

## üë• Contribution

Pour contribuer :

1. Fork le projet
2. Cr√©er une branche feature
3. Commit les changements
4. Push vers la branche
5. Ouvrir une Pull Request

---

**D√©velopp√© avec ‚ù§Ô∏è pour l'analyse des m√©dias burkinab√®**
